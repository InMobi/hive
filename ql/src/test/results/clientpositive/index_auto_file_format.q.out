PREHOOK: query: -- test automatic use of index on different file formats
CREATE INDEX src_index ON TABLE src(key) as 'COMPACT' WITH DEFERRED REBUILD
PREHOOK: type: CREATEINDEX
POSTHOOK: query: -- test automatic use of index on different file formats
CREATE INDEX src_index ON TABLE src(key) as 'COMPACT' WITH DEFERRED REBUILD
POSTHOOK: type: CREATEINDEX
POSTHOOK: Output: default@default__src_src_index__
PREHOOK: query: ALTER INDEX src_index ON src REBUILD
PREHOOK: type: ALTERINDEX_REBUILD
PREHOOK: Input: default@src
PREHOOK: Output: default@default__src_src_index__
POSTHOOK: query: ALTER INDEX src_index ON src REBUILD
POSTHOOK: type: ALTERINDEX_REBUILD
POSTHOOK: Input: default@src
POSTHOOK: Output: default@default__src_src_index__
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: EXPLAIN SELECT key, value FROM src WHERE key=86 ORDER BY key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN SELECT key, value FROM src WHERE key=86 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-8 depends on stages: Stage-3 , consists of Stage-5, Stage-4, Stage-6
  Stage-5
  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
  Stage-1 depends on stages: Stage-2
  Stage-4
  Stage-6
  Stage-7 depends on stages: Stage-6
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: default__src_src_index__
            filterExpr: (key = 86) (type: boolean)
            Filter Operator
              predicate: (key = 86) (type: boolean)
              Select Operator
                expressions: _bucketname (type: string), _offsets (type: array<bigint>)
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-5
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-2
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            filterExpr: (key = 86) (type: boolean)
            Statistics: Num rows: 29 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (key = 86) (type: boolean)
              Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col1 (type: string)
      Reduce Operator Tree:
        Extract
          Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-6
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-7
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: SELECT key, value FROM src WHERE key=86 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@default__src_src_index__
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value FROM src WHERE key=86 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@default__src_src_index__
POSTHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
86	val_86
PREHOOK: query: EXPLAIN SELECT key, value FROM src WHERE key=86 ORDER BY key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN SELECT key, value FROM src WHERE key=86 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
STAGE DEPENDENCIES:
  Stage-3 is a root stage
  Stage-8 depends on stages: Stage-3 , consists of Stage-5, Stage-4, Stage-6
  Stage-5
  Stage-2 depends on stages: Stage-5, Stage-4, Stage-7
  Stage-1 depends on stages: Stage-2
  Stage-4
  Stage-6
  Stage-7 depends on stages: Stage-6
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: default__src_src_index__
            filterExpr: (key = 86) (type: boolean)
            Filter Operator
              predicate: (key = 86) (type: boolean)
              Select Operator
                expressions: _bucketname (type: string), _offsets (type: array<bigint>)
                outputColumnNames: _col0, _col1
                File Output Operator
                  compressed: false
                  table:
                      input format: org.apache.hadoop.mapred.TextInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-8
    Conditional Operator

  Stage: Stage-5
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-2
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: src
            filterExpr: (key = 86) (type: boolean)
            Statistics: Num rows: 29 Data size: 5812 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: (key = 86) (type: boolean)
              Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: key (type: string), value (type: string)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: string), _col1 (type: string)
      Reduce Operator Tree:
        Extract
          Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 14 Data size: 2805 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.TextInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-4
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-6
    Map Reduce
      Map Operator Tree:
          TableScan
            File Output Operator
              compressed: false
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-7
    Move Operator
      files:
          hdfs directory: true
#### A masked pattern was here ####

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: SELECT key, value FROM src WHERE key=86 ORDER BY key
PREHOOK: type: QUERY
PREHOOK: Input: default@default__src_src_index__
PREHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: query: SELECT key, value FROM src WHERE key=86 ORDER BY key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@default__src_src_index__
POSTHOOK: Input: default@src
#### A masked pattern was here ####
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
86	val_86
PREHOOK: query: DROP INDEX src_index on src
PREHOOK: type: DROPINDEX
POSTHOOK: query: DROP INDEX src_index on src
POSTHOOK: type: DROPINDEX
POSTHOOK: Lineage: default__src_src_index__._bucketname SIMPLE [(src)src.FieldSchema(name:INPUT__FILE__NAME, type:string, comment:), ]
POSTHOOK: Lineage: default__src_src_index__._offsets EXPRESSION [(src)src.FieldSchema(name:BLOCK__OFFSET__INSIDE__FILE, type:bigint, comment:), ]
POSTHOOK: Lineage: default__src_src_index__.key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
