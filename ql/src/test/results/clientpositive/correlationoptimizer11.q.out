PREHOOK: query: -- Tests in this file are used to make sure Correlation Optimizer
-- can correctly handle tables with partitions

CREATE TABLE part_table(key string, value string) PARTITIONED BY (partitionId int)
PREHOOK: type: CREATETABLE
POSTHOOK: query: -- Tests in this file are used to make sure Correlation Optimizer
-- can correctly handle tables with partitions

CREATE TABLE part_table(key string, value string) PARTITIONED BY (partitionId int)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: default@part_table
PREHOOK: query: INSERT OVERWRITE TABLE part_table PARTITION (partitionId=1)
  SELECT key, value FROM src ORDER BY key, value LIMIT 100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@part_table@partitionid=1
POSTHOOK: query: INSERT OVERWRITE TABLE part_table PARTITION (partitionId=1)
  SELECT key, value FROM src ORDER BY key, value LIMIT 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@part_table@partitionid=1
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: INSERT OVERWRITE TABLE part_table PARTITION (partitionId=2)
  SELECT key, value FROM src1 ORDER BY key, value
PREHOOK: type: QUERY
PREHOOK: Input: default@src1
PREHOOK: Output: default@part_table@partitionid=2
POSTHOOK: query: INSERT OVERWRITE TABLE part_table PARTITION (partitionId=2)
  SELECT key, value FROM src1 ORDER BY key, value
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src1
POSTHOOK: Output: default@part_table@partitionid=2
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
PREHOOK: query: -- In this case, we should not do shared scan on part_table
-- because left and right tables of JOIN use different partitions
-- of part_table. With Correlation Optimizer we will generate
-- 1 MR job.
EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
POSTHOOK: query: -- In this case, we should not do shared scan on part_table
-- because left and right tables of JOIN use different partitions
-- of part_table. With Correlation Optimizer we will generate
-- 1 MR job.
EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME part_table) x) (TOK_TABREF (TOK_TABNAME part_table) y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key) key) (TOK_SELEXPR (TOK_FUNCTION count 1) cnt)) (TOK_WHERE (AND (= (. (TOK_TABLE_OR_COL x) partitionId) 1) (= (. (TOK_TABLE_OR_COL y) partitionId) 2))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL x) key))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        x 
          TableScan
            alias: x
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 0
              value expressions:
                    expr: key
                    type: string
        y 
          TableScan
            alias: y
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0
          Select Operator
            expressions:
                  expr: _col0
                  type: string
            outputColumnNames: _col0
            Group By Operator
              aggregations:
                    expr: count(1)
              bucketGroup: false
              keys:
                    expr: _col0
                    type: string
              mode: hash
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: -1
              value expressions:
                    expr: _col1
                    type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@part_table
PREHOOK: Input: default@part_table@partitionid=1
PREHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_table
POSTHOOK: Input: default@part_table@partitionid=1
POSTHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
128	3
146	2
150	1
PREHOOK: query: EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME part_table) x) (TOK_TABREF (TOK_TABNAME part_table) y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key) key) (TOK_SELEXPR (TOK_FUNCTION count 1) cnt)) (TOK_WHERE (AND (= (. (TOK_TABLE_OR_COL x) partitionId) 1) (= (. (TOK_TABLE_OR_COL y) partitionId) 2))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL x) key))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        x 
          TableScan
            alias: x
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 0
              value expressions:
                    expr: key
                    type: string
        y 
          TableScan
            alias: y
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
      Reduce Operator Tree:
        Demux Operator
          Join Operator
            condition map:
                 Inner Join 0 to 1
            condition expressions:
              0 {VALUE._col0}
              1 
            handleSkewJoin: false
            outputColumnNames: _col0
            Select Operator
              expressions:
                    expr: _col0
                    type: string
              outputColumnNames: _col0
              Mux Operator
                Group By Operator
                  aggregations:
                        expr: count(1)
                  bucketGroup: false
                  keys:
                        expr: _col0
                        type: string
                  mode: complete
                  outputColumnNames: _col0, _col1
                  Select Operator
                    expressions:
                          expr: _col0
                          type: string
                          expr: _col1
                          type: bigint
                    outputColumnNames: _col0, _col1
                    File Output Operator
                      compressed: false
                      GlobalTableId: 0
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@part_table
PREHOOK: Input: default@part_table@partitionid=1
PREHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 1 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_table
POSTHOOK: Input: default@part_table@partitionid=1
POSTHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
128	3
146	2
150	1
PREHOOK: query: -- In this case, we should do shared scan on part_table
-- because left and right tables of JOIN use the same partition
-- of part_table. With Correlation Optimizer we will generate
-- 1 MR job.
EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
POSTHOOK: query: -- In this case, we should do shared scan on part_table
-- because left and right tables of JOIN use the same partition
-- of part_table. With Correlation Optimizer we will generate
-- 1 MR job.
EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME part_table) x) (TOK_TABREF (TOK_TABNAME part_table) y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key) key) (TOK_SELEXPR (TOK_FUNCTION count 1) cnt)) (TOK_WHERE (AND (= (. (TOK_TABLE_OR_COL x) partitionId) 2) (= (. (TOK_TABLE_OR_COL y) partitionId) 2))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL x) key))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        x 
          TableScan
            alias: x
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 0
              value expressions:
                    expr: key
                    type: string
        y 
          TableScan
            alias: y
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
      Reduce Operator Tree:
        Join Operator
          condition map:
               Inner Join 0 to 1
          condition expressions:
            0 {VALUE._col0}
            1 
          handleSkewJoin: false
          outputColumnNames: _col0
          Select Operator
            expressions:
                  expr: _col0
                  type: string
            outputColumnNames: _col0
            Group By Operator
              aggregations:
                    expr: count(1)
              bucketGroup: false
              keys:
                    expr: _col0
                    type: string
              mode: hash
              outputColumnNames: _col0, _col1
              File Output Operator
                compressed: false
                GlobalTableId: 0
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat

  Stage: Stage-2
    Map Reduce
      Alias -> Map Operator Tree:
#### A masked pattern was here ####
            Reduce Output Operator
              key expressions:
                    expr: _col0
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: _col0
                    type: string
              tag: -1
              value expressions:
                    expr: _col1
                    type: bigint
      Reduce Operator Tree:
        Group By Operator
          aggregations:
                expr: count(VALUE._col0)
          bucketGroup: false
          keys:
                expr: KEY._col0
                type: string
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Select Operator
            expressions:
                  expr: _col0
                  type: string
                  expr: _col1
                  type: bigint
            outputColumnNames: _col0, _col1
            File Output Operator
              compressed: false
              GlobalTableId: 0
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@part_table
PREHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_table
POSTHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
	100
128	1
146	1
150	1
213	1
224	1
238	1
255	1
273	1
278	1
311	1
369	1
401	1
406	1
66	1
98	1
PREHOOK: query: EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
POSTHOOK: query: EXPLAIN
SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_JOIN (TOK_TABREF (TOK_TABNAME part_table) x) (TOK_TABREF (TOK_TABNAME part_table) y) (= (. (TOK_TABLE_OR_COL x) key) (. (TOK_TABLE_OR_COL y) key)))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL x) key) key) (TOK_SELEXPR (TOK_FUNCTION count 1) cnt)) (TOK_WHERE (AND (= (. (TOK_TABLE_OR_COL x) partitionId) 2) (= (. (TOK_TABLE_OR_COL y) partitionId) 2))) (TOK_GROUPBY (. (TOK_TABLE_OR_COL x) key))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        x 
          TableScan
            alias: x
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 0
              value expressions:
                    expr: key
                    type: string
        y 
          TableScan
            alias: y
            Reduce Output Operator
              key expressions:
                    expr: key
                    type: string
              sort order: +
              Map-reduce partition columns:
                    expr: key
                    type: string
              tag: 1
      Reduce Operator Tree:
        Demux Operator
          Join Operator
            condition map:
                 Inner Join 0 to 1
            condition expressions:
              0 {VALUE._col0}
              1 
            handleSkewJoin: false
            outputColumnNames: _col0
            Select Operator
              expressions:
                    expr: _col0
                    type: string
              outputColumnNames: _col0
              Mux Operator
                Group By Operator
                  aggregations:
                        expr: count(1)
                  bucketGroup: false
                  keys:
                        expr: _col0
                        type: string
                  mode: complete
                  outputColumnNames: _col0, _col1
                  Select Operator
                    expressions:
                          expr: _col0
                          type: string
                          expr: _col1
                          type: bigint
                    outputColumnNames: _col0, _col1
                    File Output Operator
                      compressed: false
                      GlobalTableId: 0
                      table:
                          input format: org.apache.hadoop.mapred.TextInputFormat
                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
PREHOOK: type: QUERY
PREHOOK: Input: default@part_table
PREHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: query: SELECT x.key AS key, count(1) AS cnt
FROM part_table x JOIN part_table y ON (x.key = y.key)
WHERE x.partitionId = 2 AND
      y.partitionId = 2
GROUP BY x.key
POSTHOOK: type: QUERY
POSTHOOK: Input: default@part_table
POSTHOOK: Input: default@part_table@partitionid=2
#### A masked pattern was here ####
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).key SIMPLE [(src1)src1.FieldSchema(name:key, type:string, comment:default), ]
POSTHOOK: Lineage: part_table PARTITION(partitionid=2).value SIMPLE [(src1)src1.FieldSchema(name:value, type:string, comment:default), ]
	100
128	1
146	1
150	1
213	1
224	1
238	1
255	1
273	1
278	1
311	1
369	1
401	1
406	1
66	1
98	1
