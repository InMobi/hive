PREHOOK: query: -- HIVE-2906 Table properties in SQL

explain extended select key from src
PREHOOK: type: QUERY
POSTHOOK: query: -- HIVE-2906 Table properties in SQL

explain extended select key from src
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [src]

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: explain extended select a.key from src a
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select a.key from src a
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [a]

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: explain extended select a.key from src tablesample(1 percent) a
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select a.key from src tablesample(1 percent) a
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) (TOK_TABLESPLITSAMPLE TOK_PERCENT 1) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Split Sample:
        a 
            percentage: 1.0
            seed number: 0
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [a]

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: explain extended select key from src ('user.defined.key'='some.value')
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key from src ('user.defined.key'='some.value')
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY 'user.defined.key' 'some.value'))))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
              user.defined.key some.value
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
                user.defined.key some.value
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [src]

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: explain extended select key from src ('user.defined.key'='some.value') tablesample(1 percent)
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select key from src ('user.defined.key'='some.value') tablesample(1 percent)
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY 'user.defined.key' 'some.value'))) (TOK_TABLESPLITSAMPLE TOK_PERCENT 1))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (TOK_TABLE_OR_COL key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        src 
          TableScan
            alias: src
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Split Sample:
        src 
            percentage: 1.0
            seed number: 0
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
              user.defined.key some.value
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
                user.defined.key some.value
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [src]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: explain extended select a.key from src ('user.defined.key'='some.value') a
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select a.key from src ('user.defined.key'='some.value') a
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY 'user.defined.key' 'some.value'))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
              user.defined.key some.value
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
                user.defined.key some.value
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [a]

  Stage: Stage-0
    Fetch Operator
      limit: -1


PREHOOK: query: explain extended select a.key from src ('user.defined.key'='some.value') tablesample(1 percent) a
PREHOOK: type: QUERY
POSTHOOK: query: explain extended select a.key from src ('user.defined.key'='some.value') tablesample(1 percent) a
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src) (TOK_TABLEPROPERTIES (TOK_TABLEPROPLIST (TOK_TABLEPROPERTY 'user.defined.key' 'some.value'))) (TOK_TABLESPLITSAMPLE TOK_PERCENT 1) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR (. (TOK_TABLE_OR_COL a) key)))))

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Alias -> Map Operator Tree:
        a 
          TableScan
            alias: a
            GatherStats: false
            Select Operator
              expressions:
                    expr: key
                    type: string
              outputColumnNames: _col0
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Split Sample:
        a 
            percentage: 1.0
            seed number: 0
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: src
            input format: org.apache.hadoop.mapred.TextInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
            properties:
              bucket_count -1
              columns key,value
              columns.types string:string
#### A masked pattern was here ####
              name default.src
              numFiles 1
              numPartitions 0
              numRows 0
              rawDataSize 0
              serialization.ddl struct src { string key, string value}
              serialization.format 1
              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              totalSize 5812
#### A masked pattern was here ####
              user.defined.key some.value
            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          
              input format: org.apache.hadoop.mapred.TextInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
              properties:
                bucket_count -1
                columns key,value
                columns.types string:string
#### A masked pattern was here ####
                name default.src
                numFiles 1
                numPartitions 0
                numRows 0
                rawDataSize 0
                serialization.ddl struct src { string key, string value}
                serialization.format 1
                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                totalSize 5812
#### A masked pattern was here ####
                user.defined.key some.value
              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              name: default.src
            name: default.src
      Truncated Path -> Alias:
        /src [a]

  Stage: Stage-0
    Fetch Operator
      limit: -1

