PREHOOK: query: create table if not exists loc_staging (
  state string,
  locid int,
  zip bigint,
  year int
) row format delimited fields terminated by '|' stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
POSTHOOK: query: create table if not exists loc_staging (
  state string,
  locid int,
  zip bigint,
  year int
) row format delimited fields terminated by '|' stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@loc_staging
PREHOOK: query: create table loc_orc like loc_staging
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
POSTHOOK: query: create table loc_orc like loc_staging
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@loc_orc
PREHOOK: query: alter table loc_orc set fileformat orc
PREHOOK: type: ALTERTABLE_FILEFORMAT
PREHOOK: Input: default@loc_orc
PREHOOK: Output: default@loc_orc
POSTHOOK: query: alter table loc_orc set fileformat orc
POSTHOOK: type: ALTERTABLE_FILEFORMAT
POSTHOOK: Input: default@loc_orc
POSTHOOK: Output: default@loc_orc
PREHOOK: query: load data local inpath '../../data/files/loc.txt' overwrite into table loc_staging
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@loc_staging
POSTHOOK: query: load data local inpath '../../data/files/loc.txt' overwrite into table loc_staging
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@loc_staging
PREHOOK: query: insert overwrite table loc_orc select * from loc_staging
PREHOOK: type: QUERY
PREHOOK: Input: default@loc_staging
PREHOOK: Output: default@loc_orc
POSTHOOK: query: insert overwrite table loc_orc select * from loc_staging
POSTHOOK: type: QUERY
POSTHOOK: Input: default@loc_staging
POSTHOOK: Output: default@loc_orc
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
PREHOOK: query: -- numRows: 8 rawDataSize: 796
explain extended select * from loc_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- numRows: 8 rawDataSize: 796
explain extended select * from loc_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: loc_orc
          Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: NONE
          GatherStats: false
          Select Operator
            expressions: state (type: string), locid (type: int), zip (type: bigint), year (type: int)
            outputColumnNames: _col0, _col1, _col2, _col3
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: NONE
            ListSink

PREHOOK: query: -- partial column stats
analyze table loc_orc compute statistics for columns state
PREHOOK: type: QUERY
PREHOOK: Input: default@loc_orc
#### A masked pattern was here ####
POSTHOOK: query: -- partial column stats
analyze table loc_orc compute statistics for columns state
POSTHOOK: type: QUERY
POSTHOOK: Input: default@loc_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
PREHOOK: query: -- inner group by: map - numRows: 8 reduce - numRows: 4
-- outer group by: map - numRows: 4 reduce numRows: 2
explain extended select a, c, min(b)
from ( select state as a, locid as b, count(*) as c
       from loc_orc
       group by state,locid
     ) sq1
group by a,c
PREHOOK: type: QUERY
POSTHOOK: query: -- inner group by: map - numRows: 8 reduce - numRows: 4
-- outer group by: map - numRows: 4 reduce numRows: 2
explain extended select a, c, min(b)
from ( select state as a, locid as b, count(*) as c
       from loc_orc
       group by state,locid
     ) sq1
group by a,c
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_SUBQUERY
         TOK_QUERY
            TOK_FROM
               TOK_TABREF
                  TOK_TABNAME
                     loc_orc
            TOK_INSERT
               TOK_DESTINATION
                  TOK_DIR
                     TOK_TMP_FILE
               TOK_SELECT
                  TOK_SELEXPR
                     TOK_TABLE_OR_COL
                        state
                     a
                  TOK_SELEXPR
                     TOK_TABLE_OR_COL
                        locid
                     b
                  TOK_SELEXPR
                     TOK_FUNCTIONSTAR
                        count
                     c
               TOK_GROUPBY
                  TOK_TABLE_OR_COL
                     state
                  TOK_TABLE_OR_COL
                     locid
         sq1
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               a
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               c
         TOK_SELEXPR
            TOK_FUNCTION
               min
               TOK_TABLE_OR_COL
                  b
      TOK_GROUPBY
         TOK_TABLE_OR_COL
            a
         TOK_TABLE_OR_COL
            c


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: PARTIAL
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: PARTIAL
              Group By Operator
                aggregations: count()
                keys: state (type: string), locid (type: int)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 8 Data size: 688 Basic stats: COMPLETE Column stats: PARTIAL
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int)
                  Statistics: Num rows: 8 Data size: 688 Basic stats: COMPLETE Column stats: PARTIAL
                  tag: -1
                  value expressions: _col2 (type: bigint)
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [sq1:loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          aggregations: count(VALUE._col0)
          keys: KEY._col0 (type: string), KEY._col1 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 4 Data size: 344 Basic stats: COMPLETE Column stats: PARTIAL
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int), _col2 (type: bigint)
            outputColumnNames: _col0, _col1, _col2
            Statistics: Num rows: 4 Data size: 344 Basic stats: COMPLETE Column stats: PARTIAL
            Group By Operator
              aggregations: min(_col1)
              keys: _col0 (type: string), _col2 (type: bigint)
              mode: hash
              outputColumnNames: _col0, _col1, _col2
              Statistics: Num rows: 4 Data size: 376 Basic stats: COMPLETE Column stats: PARTIAL
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    properties:
                      columns _col0,_col1,_col2
                      columns.types string,bigint,int
                      escape.delim \
                      serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                    serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            GatherStats: false
            Reduce Output Operator
              key expressions: _col0 (type: string), _col1 (type: bigint)
              sort order: ++
              Map-reduce partition columns: _col0 (type: string), _col1 (type: bigint)
              Statistics: Num rows: 4 Data size: 376 Basic stats: COMPLETE Column stats: PARTIAL
              tag: -1
              value expressions: _col2 (type: int)
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: -mr-10002
            input format: org.apache.hadoop.mapred.SequenceFileInputFormat
            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
            properties:
              columns _col0,_col1,_col2
              columns.types string,bigint,int
              escape.delim \
              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
          
              input format: org.apache.hadoop.mapred.SequenceFileInputFormat
              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
              properties:
                columns _col0,_col1,_col2
                columns.types string,bigint,int
                escape.delim \
                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
      Truncated Path -> Alias:
#### A masked pattern was here ####
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          aggregations: min(VALUE._col0)
          keys: KEY._col0 (type: string), KEY._col1 (type: bigint)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 2 Data size: 188 Basic stats: COMPLETE Column stats: PARTIAL
          Select Operator
            expressions: _col0 (type: string), _col1 (type: bigint), _col2 (type: int)
            outputColumnNames: _col0, _col1, _col2
            Statistics: Num rows: 2 Data size: 196 Basic stats: COMPLETE Column stats: PARTIAL
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 2 Data size: 196 Basic stats: COMPLETE Column stats: PARTIAL
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1,_col2
                    columns.types string:bigint:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: analyze table loc_orc compute statistics for columns state,locid,zip,year
PREHOOK: type: QUERY
PREHOOK: Input: default@loc_orc
#### A masked pattern was here ####
POSTHOOK: query: analyze table loc_orc compute statistics for columns state,locid,zip,year
POSTHOOK: type: QUERY
POSTHOOK: Input: default@loc_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
PREHOOK: query: -- only one distinct value in year column + 1 NULL value
-- map-side GBY: numRows: 8 (map-side will not do any reduction)
-- reduce-side GBY: numRows: 2
explain extended select year from loc_orc group by year
PREHOOK: type: QUERY
POSTHOOK: query: -- only one distinct value in year column + 1 NULL value
-- map-side GBY: numRows: 8 (map-side will not do any reduction)
-- reduce-side GBY: numRows: 2
explain extended select year from loc_orc group by year
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               year
      TOK_GROUPBY
         TOK_TABLE_OR_COL
            year


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: year (type: int)
              outputColumnNames: year
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: year (type: int)
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 8 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 8 Data size: 28 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: int)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: int)
            outputColumnNames: _col0
            Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0
                    columns.types int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY: numRows: 8
-- reduce-side GBY: numRows: 4
explain extended select state,locid from loc_orc group by state,locid
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY: numRows: 8
-- reduce-side GBY: numRows: 4
explain extended select state,locid from loc_orc group by state,locid
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_GROUPBY
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 8 Data size: 720 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int)
                  sort order: ++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int)
                  Statistics: Num rows: 8 Data size: 720 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 4 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 4 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 4 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 32 reduce-side GBY numRows: 16
explain extended select state,locid from loc_orc group by state,locid with cube
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 32 reduce-side GBY numRows: 16
explain extended select state,locid from loc_orc group by state,locid with cube
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_CUBE_GROUPBY
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 32 Data size: 3184 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 32 Data size: 3184 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 16 Data size: 2800 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 16 Data size: 1440 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 16 Data size: 1440 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 24 reduce-side GBY numRows: 12
explain extended select state,locid from loc_orc group by state,locid with rollup
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 24 reduce-side GBY numRows: 12
explain extended select state,locid from loc_orc group by state,locid with rollup
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_ROLLUP_GROUPBY
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 24 Data size: 2388 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 24 Data size: 2388 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 12 Data size: 2100 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 12 Data size: 1080 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 12 Data size: 1080 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 8 reduce-side GBY numRows: 4
explain extended select state,locid from loc_orc group by state,locid grouping sets((state))
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 8 reduce-side GBY numRows: 4
explain extended select state,locid from loc_orc group by state,locid grouping sets((state))
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_GROUPING_SETS
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               state


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 4 Data size: 700 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 4 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 4 Data size: 360 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 16 reduce-side GBY numRows: 8
explain extended select state,locid from loc_orc group by state,locid grouping sets((state),(locid))
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 16 reduce-side GBY numRows: 8
explain extended select state,locid from loc_orc group by state,locid grouping sets((state),(locid))
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_GROUPING_SETS
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               state
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               locid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 16 Data size: 1592 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 16 Data size: 1592 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 8 Data size: 1400 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 8 Data size: 720 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 8 Data size: 720 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 24 reduce-side GBY numRows: 12
explain extended select state,locid from loc_orc group by state,locid grouping sets((state),(locid),())
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 24 reduce-side GBY numRows: 12
explain extended select state,locid from loc_orc group by state,locid grouping sets((state),(locid),())
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_GROUPING_SETS
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               state
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               locid
         TOK_GROUPING_SETS_EXPRESSION


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 24 Data size: 2388 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 24 Data size: 2388 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 12 Data size: 2100 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 12 Data size: 1080 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 12 Data size: 1080 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 32 reduce-side GBY numRows: 16
explain extended select state,locid from loc_orc group by state,locid grouping sets((state,locid),(state),(locid),())
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 32 reduce-side GBY numRows: 16
explain extended select state,locid from loc_orc group by state,locid grouping sets((state,locid),(state),(locid),())
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_GROUPING_SETS
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               state
            TOK_TABLE_OR_COL
               locid
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               state
         TOK_GROUPING_SETS_EXPRESSION
            TOK_TABLE_OR_COL
               locid
         TOK_GROUPING_SETS_EXPRESSION


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 32 Data size: 3184 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 32 Data size: 3184 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 16 Data size: 2800 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 16 Data size: 1440 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 16 Data size: 1440 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY: numRows: 80 (map-side will not do any reduction)
-- reduce-side GBY: numRows: 2 Reason: numDistinct of year is 2. numRows = min(80/2, 2)
explain extended select year from loc_orc group by year
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY: numRows: 80 (map-side will not do any reduction)
-- reduce-side GBY: numRows: 2 Reason: numDistinct of year is 2. numRows = min(80/2, 2)
explain extended select year from loc_orc group by year
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               year
      TOK_GROUPBY
         TOK_TABLE_OR_COL
            year


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: year (type: int)
              outputColumnNames: year
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: year (type: int)
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 80 Data size: 280 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: int)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: int)
                  Statistics: Num rows: 80 Data size: 280 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: int)
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: int)
            outputColumnNames: _col0
            Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 2 Data size: 8 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0
                    columns.types int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- map-side GBY numRows: 320 reduce-side GBY numRows: 42 Reason: numDistinct of state and locid are 6,7 resp. numRows = min(320/2, 6*7)
explain extended select state,locid from loc_orc group by state,locid with cube
PREHOOK: type: QUERY
POSTHOOK: query: -- map-side GBY numRows: 320 reduce-side GBY numRows: 42 Reason: numDistinct of state and locid are 6,7 resp. numRows = min(320/2, 6*7)
explain extended select state,locid from loc_orc group by state,locid with cube
POSTHOOK: type: QUERY
POSTHOOK: Lineage: loc_orc.locid SIMPLE [(loc_staging)loc_staging.FieldSchema(name:locid, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.state SIMPLE [(loc_staging)loc_staging.FieldSchema(name:state, type:string, comment:null), ]
POSTHOOK: Lineage: loc_orc.year SIMPLE [(loc_staging)loc_staging.FieldSchema(name:year, type:int, comment:null), ]
POSTHOOK: Lineage: loc_orc.zip SIMPLE [(loc_staging)loc_staging.FieldSchema(name:zip, type:bigint, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            loc_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               state
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               locid
      TOK_CUBE_GROUPBY
         TOK_TABLE_OR_COL
            state
         TOK_TABLE_OR_COL
            locid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: loc_orc
            Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: state (type: string), locid (type: int)
              outputColumnNames: state, locid
              Statistics: Num rows: 8 Data size: 796 Basic stats: COMPLETE Column stats: COMPLETE
              Group By Operator
                keys: state (type: string), locid (type: int), '0' (type: string)
                mode: hash
                outputColumnNames: _col0, _col1, _col2
                Statistics: Num rows: 320 Data size: 31840 Basic stats: COMPLETE Column stats: COMPLETE
                Reduce Output Operator
                  key expressions: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  sort order: +++
                  Map-reduce partition columns: _col0 (type: string), _col1 (type: int), _col2 (type: string)
                  Statistics: Num rows: 320 Data size: 31840 Basic stats: COMPLETE Column stats: COMPLETE
                  tag: -1
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: loc_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns state,locid,zip,year
              columns.comments    
              columns.types string:int:bigint:int
              field.delim |
#### A masked pattern was here ####
              name default.loc_orc
              numFiles 1
              numRows 8
              rawDataSize 796
              serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 489
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns state,locid,zip,year
                columns.comments    
                columns.types string:int:bigint:int
                field.delim |
#### A masked pattern was here ####
                name default.loc_orc
                numFiles 1
                numRows 8
                rawDataSize 796
                serialization.ddl struct loc_orc { string state, i32 locid, i64 zip, i32 year}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 489
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.loc_orc
            name: default.loc_orc
      Truncated Path -> Alias:
        /loc_orc [loc_orc]
      Needs Tagging: false
      Reduce Operator Tree:
        Group By Operator
          keys: KEY._col0 (type: string), KEY._col1 (type: int), KEY._col2 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1, _col2
          Statistics: Num rows: 42 Data size: 7350 Basic stats: COMPLETE Column stats: COMPLETE
          Select Operator
            expressions: _col0 (type: string), _col1 (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 42 Data size: 3780 Basic stats: COMPLETE Column stats: COMPLETE
            File Output Operator
              compressed: false
              GlobalTableId: 0
#### A masked pattern was here ####
              NumFilesPerFileSink: 1
              Statistics: Num rows: 42 Data size: 3780 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
              table:
                  input format: org.apache.hadoop.mapred.TextInputFormat
                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                  properties:
                    columns _col0,_col1
                    columns.types string:int
                    escape.delim \
                    hive.serialization.extend.nesting.levels true
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
              TotalFiles: 1
              GatherStats: false
              MultiFileSpray: false

  Stage: Stage-0
    Fetch Operator
      limit: -1

