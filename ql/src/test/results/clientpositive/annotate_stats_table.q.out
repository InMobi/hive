PREHOOK: query: create table if not exists emp_staging (
  lastname string,
  deptid int
) row format delimited fields terminated by '|' stored as textfile
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
POSTHOOK: query: create table if not exists emp_staging (
  lastname string,
  deptid int
) row format delimited fields terminated by '|' stored as textfile
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@emp_staging
PREHOOK: query: create table if not exists emp_orc like emp_staging
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
POSTHOOK: query: create table if not exists emp_orc like emp_staging
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@emp_orc
PREHOOK: query: alter table emp_orc set fileformat orc
PREHOOK: type: ALTERTABLE_FILEFORMAT
PREHOOK: Input: default@emp_orc
PREHOOK: Output: default@emp_orc
POSTHOOK: query: alter table emp_orc set fileformat orc
POSTHOOK: type: ALTERTABLE_FILEFORMAT
POSTHOOK: Input: default@emp_orc
POSTHOOK: Output: default@emp_orc
PREHOOK: query: -- basicStatState: NONE colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: NONE colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
          GatherStats: false
          Select Operator
            expressions: lastname (type: string), deptid (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
            ListSink

PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/emp.txt' OVERWRITE INTO TABLE emp_staging
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@emp_staging
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/emp.txt' OVERWRITE INTO TABLE emp_staging
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@emp_staging
PREHOOK: query: insert overwrite table emp_orc select * from emp_staging
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_staging
PREHOOK: Output: default@emp_orc
POSTHOOK: query: insert overwrite table emp_orc select * from emp_staging
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_staging
POSTHOOK: Output: default@emp_orc
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- stats are disabled. basic stats will report the file size but not raw data size. so initial statistics will be PARTIAL

-- basicStatState: PARTIAL colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- stats are disabled. basic stats will report the file size but not raw data size. so initial statistics will be PARTIAL

-- basicStatState: PARTIAL colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics: Num rows: 3 Data size: 349 Basic stats: COMPLETE Column stats: NONE
          GatherStats: false
          Select Operator
            expressions: lastname (type: string), deptid (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 3 Data size: 349 Basic stats: COMPLETE Column stats: NONE
            ListSink

PREHOOK: query: -- table level analyze statistics
analyze table emp_orc compute statistics
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
PREHOOK: Output: default@emp_orc
POSTHOOK: query: -- table level analyze statistics
analyze table emp_orc compute statistics
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
POSTHOOK: Output: default@emp_orc
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: NONE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: NONE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: NONE
          GatherStats: false
          Select Operator
            expressions: lastname (type: string), deptid (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: NONE
            ListSink

PREHOOK: query: -- column level partial statistics
analyze table emp_orc compute statistics for columns deptid
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: query: -- column level partial statistics
analyze table emp_orc compute statistics for columns deptid
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: PARTIAL
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: PARTIAL
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: PARTIAL
          GatherStats: false
          Select Operator
            expressions: lastname (type: string), deptid (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: PARTIAL
            ListSink

PREHOOK: query: -- all selected columns have statistics
-- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- all selected columns have statistics
-- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               deptid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: emp_orc
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: deptid (type: int)
              outputColumnNames: _col0
              Statistics: Num rows: 6 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 6 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.comments  
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.comments  
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- column level complete statistics
analyze table emp_orc compute statistics for columns lastname,deptid
PREHOOK: type: QUERY
PREHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: query: -- column level complete statistics
analyze table emp_orc compute statistics for columns lastname,deptid
POSTHOOK: type: QUERY
POSTHOOK: Input: default@emp_orc
#### A masked pattern was here ####
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select * from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select * from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_ALLCOLREF


STAGE DEPENDENCIES:
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        TableScan
          alias: emp_orc
          Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
          GatherStats: false
          Select Operator
            expressions: lastname (type: string), deptid (type: int)
            outputColumnNames: _col0, _col1
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
            ListSink

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               lastname


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: emp_orc
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: lastname (type: string)
              outputColumnNames: _col0
              Statistics: Num rows: 6 Data size: 546 Basic stats: COMPLETE Column stats: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 6 Data size: 546 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types string
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.comments  
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.comments  
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               deptid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: emp_orc
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: deptid (type: int)
              outputColumnNames: _col0
              Statistics: Num rows: 6 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 6 Data size: 20 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0
                      columns.types int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.comments  
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.comments  
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

PREHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname,deptid from emp_orc
PREHOOK: type: QUERY
POSTHOOK: query: -- basicStatState: COMPLETE colStatState: COMPLETE
explain extended select lastname,deptid from emp_orc
POSTHOOK: type: QUERY
POSTHOOK: Lineage: emp_orc.deptid SIMPLE [(emp_staging)emp_staging.FieldSchema(name:deptid, type:int, comment:null), ]
POSTHOOK: Lineage: emp_orc.lastname SIMPLE [(emp_staging)emp_staging.FieldSchema(name:lastname, type:string, comment:null), ]
ABSTRACT SYNTAX TREE:
  
TOK_QUERY
   TOK_FROM
      TOK_TABREF
         TOK_TABNAME
            emp_orc
   TOK_INSERT
      TOK_DESTINATION
         TOK_DIR
            TOK_TMP_FILE
      TOK_SELECT
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               lastname
         TOK_SELEXPR
            TOK_TABLE_OR_COL
               deptid


STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 is a root stage

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: emp_orc
            Statistics: Num rows: 6 Data size: 349 Basic stats: COMPLETE Column stats: COMPLETE
            GatherStats: false
            Select Operator
              expressions: lastname (type: string), deptid (type: int)
              outputColumnNames: _col0, _col1
              Statistics: Num rows: 6 Data size: 566 Basic stats: COMPLETE Column stats: COMPLETE
              File Output Operator
                compressed: false
                GlobalTableId: 0
#### A masked pattern was here ####
                NumFilesPerFileSink: 1
                Statistics: Num rows: 6 Data size: 566 Basic stats: COMPLETE Column stats: COMPLETE
#### A masked pattern was here ####
                table:
                    input format: org.apache.hadoop.mapred.TextInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
                    properties:
                      columns _col0,_col1
                      columns.types string:int
                      escape.delim \
                      hive.serialization.extend.nesting.levels true
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
                TotalFiles: 1
                GatherStats: false
                MultiFileSpray: false
      Path -> Alias:
#### A masked pattern was here ####
      Path -> Partition:
#### A masked pattern was here ####
          Partition
            base file name: emp_orc
            input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
            output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
            properties:
              COLUMN_STATS_ACCURATE true
              bucket_count -1
              columns lastname,deptid
              columns.comments  
              columns.types string:int
              field.delim |
#### A masked pattern was here ####
              name default.emp_orc
              numFiles 1
              numRows 6
              rawDataSize 0
              serialization.ddl struct emp_orc { string lastname, i32 deptid}
              serialization.format |
              serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
              totalSize 349
#### A masked pattern was here ####
            serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          
              input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
              output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
              properties:
                COLUMN_STATS_ACCURATE true
                bucket_count -1
                columns lastname,deptid
                columns.comments  
                columns.types string:int
                field.delim |
#### A masked pattern was here ####
                name default.emp_orc
                numFiles 1
                numRows 6
                rawDataSize 0
                serialization.ddl struct emp_orc { string lastname, i32 deptid}
                serialization.format |
                serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                totalSize 349
#### A masked pattern was here ####
              serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
              name: default.emp_orc
            name: default.emp_orc
      Truncated Path -> Alias:
        /emp_orc [emp_orc]

  Stage: Stage-0
    Fetch Operator
      limit: -1

